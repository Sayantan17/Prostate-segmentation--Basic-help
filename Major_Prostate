{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Major_Prostate","provenance":[{"file_id":"/v2/external/notebooks/editor_details.ipynb","timestamp":1576418296596}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"O83Mxr2V2aa5","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir(\"/content/drive/My Drive/Prostate/Prostate deep/\")\n","!ls\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5dVkFiu5R0pJ","colab_type":"code","colab":{}},"source":["!pip install SimpleITK\n","!pip install pydrive \n","!pip install pydicom\n","!pip install pynrrd\n","import numpy as np \n","import numpy as np\n","import tensorflow as tf\n","import time\n","import os\n","import sys\n","import pydicom\n","import nrrd\n","import scipy.ndimage\n","import scipy.misc\n","import pickle\n","import random\n","import skimage\n","%matplotlib notebook"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dv2oo0xxejVc","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as pl\n","try:\n","    get_ipython().magic(\"matplotlib inline\")\n","except:\n","    pl.ion()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MunIGmfoSpfn","colab_type":"code","colab":{}},"source":["def return_dcm(file_path, check_term = 'Prostate'):\n","    out_dcm = {}\n","    for dirName, subdirList, fileList in os.walk(file_path):\n","        c_dcm = []\n","        cur_name = \"\"\n","        dir_split = dirName.split(\"/\")\n","        for f_chk in dir_split:\n","            if check_term in f_chk:\n","                cur_name = f_chk\n","        for filename in fileList:\n","            if \".dcm\" in filename.lower():\n","                name = int(os.path.splitext(filename)[0])\n","                c_dcm.append((os.path.join(dirName,filename), name))\n","        if len(c_dcm) > 0:\n","            c_dcm = sorted(c_dcm, key = lambda t: t[1]) # Sort into correct order\n","            out_dcm[cur_name] = [c[0] for c in c_dcm]   # Store in dictionary\n","    return out_dcm\n","\n","def return_nrrd(file_path):\n","    out_nrrd = {}\n","    for dirName, subdirList, fileList in os.walk(file_path):\n","        for filename in fileList:\n","            if \".nrrd\" in filename.lower():\n","                name = filename.split('_')[0] \n","                name = name.split('.')[0] # Get annotation name and store in dictionary\n","                out_nrrd[name] = os.path.join(dirName,filename)\n","    return out_nrrd\n","\n","def get_dataset(data_dir, anns_dir):\n","    data_out = []\n","    shapes = {}\n","    d_dcm = return_dcm(data_dir)\n","    d_nrrd = return_nrrd(anns_dir)\n","    for i in d_nrrd:\n","        seg, opts = nrrd.read(d_nrrd[i])\n","        voxels = np.zeros(np.shape(seg))\n","        for j in range(len(d_dcm[i])):\n","            dicom_ref = pydicom.read_file(d_dcm[i][j])\n","            found = False\n","            chk_val = dicom_ref[(\"0020\", \"0013\")].value \n","            if int(chk_val.__str__()) - 1 < np.shape(voxels)[-1]:\n","                voxels[:, :, int(chk_val.__str__()) - 1] = dicom_ref.pixel_array\n","            else: \n","                print('Index: ',str(int(chk_val.__str__()) - 1), ' too large for ', i, ' skipping!')\n","        seg = scipy.ndimage.interpolation.rotate(seg, 90, reshape = False)\n","        for i in range(np.shape(seg)[2]):\n","            cur_img = np.squeeze(seg[:, :, i])\n","            seg[:, :, i] = np.flipud(cur_img)\n","        if voxels.shape in shapes:\n","            shapes[voxels.shape] += 1\n","        else:\n","            shapes[voxels.shape] = 1\n","        data_out.append((voxels, seg))\n","    return data_out\n","\n","def plot_slice(slice_in, is_anns = False, num_anns = 4):\n","    slice_in = np.squeeze(slice_in)\n","    pl.figure()\n","    pl.set_cmap(pl.bone())\n","    if is_anns:\n","        pl.pcolormesh(slice_in, vmin = 0, vmax = num_anns - 1)\n","    else:\n","        pl.pcolormesh(slice_in)\n","    pl.show()\n","\n","\n","def multi_slice_viewer(feats, anns = None, preds = None, num_classes = 4, no_axis=False):\n","    if anns is None:\n","        fig, ax = pl.subplots()\n","        ax.volume = feats\n","        ax.index = feats.shape[-1] // 2\n","        ax.imshow(feats[:, :, ax.index],  cmap='bone')\n","        fig.canvas.mpl_connect('key_press_event', process_key)\n","    else:\n","        if preds is None:\n","            fig, axarr = pl.subplots(1, 2)\n","            pl.tight_layout()\n","            axarr[0].volume = feats\n","            axarr[0].index = 0\n","            axarr[0].imshow(feats[:, :, axarr[0].index],  cmap='bone')\n","            axarr[0].set_title('Scans')\n","            axarr[1].volume = anns\n","            axarr[1].index = 0\n","            axarr[1].imshow(anns[:, :, axarr[1].index],  cmap='bone', vmin = 0, vmax = num_classes)\n","            axarr[1].set_title('Annotations')\n","            fig.canvas.mpl_connect('key_press_event', process_key)\n","        else:\n","            fig, axarr = pl.subplots(1, 3)\n","            pl.tight_layout()\n","            axarr[0].volume = feats\n","            axarr[0].index = 0\n","            axarr[0].imshow(feats[:, :, axarr[0].index],  cmap='bone')\n","            axarr[0].set_title('Scans')\n","            axarr[1].volume = anns\n","            axarr[1].index = 0\n","            axarr[1].imshow(anns[:, :, axarr[1].index],  cmap='bone', vmin = 0, vmax = num_classes)\n","            axarr[1].set_title('Annotations')\n","            axarr[2].volume = preds\n","            axarr[2].index = 0\n","            axarr[2].imshow(preds[:, :, axarr[2].index],  cmap='bone', vmin = 0, vmax = num_classes)\n","            axarr[2].set_title('Predictions')\n","            fig.canvas.mpl_connect('key_press_event', process_key)\n","        if no_axis:\n","            for a in axarr:\n","                a.set_axis_off()\n","            \n","def process_key(event):\n","    fig = event.canvas.figure\n","    if event.key == 'j':\n","        for ax in fig.axes: \n","            previous_slice(ax)\n","    elif event.key == 'k':\n","        for ax in fig.axes: \n","            next_slice(ax)            \n","    fig.canvas.draw()\n","\n","def previous_slice(ax):\n","    volume = ax.volume\n","    ax.index = (ax.index - 1) % volume.shape[-1]  # wrap around using %\n","    ax.images[0].set_array(volume[:, :, ax.index])\n","\n","def next_slice(ax):\n","    volume = ax.volume\n","    ax.index = (ax.index + 1) % volume.shape[-1]\n","    ax.images[0].set_array(volume[:, :, ax.index])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Df_sfKS9uA4n","colab_type":"code","colab":{}},"source":["data_train_dir = '/content/drive/My Drive/Prostate/Prostate deep/data/train/'              \n","data_leader_dir = '/content/drive/My Drive/Prostate/Prostate deep/data/leaderboard/' \n","data_test_dir = '/content/drive/My Drive/Prostate/Prostate deep/data/test/'\n","anns_train_dir = '/content/drive/My Drive/Prostate/Prostate deep/data/train-segm/'         \n","anns_leader_dir = '/content/drive/My Drive/Prostate/Prostate deep/data/leaderboard-segm/'   \n","anns_test_dir = '/content/drive/My Drive/Prostate/Prostate deep/data/test-segm/'          \n","train = get_dataset(data_train_dir, anns_train_dir)\n","valid = get_dataset(data_leader_dir, anns_leader_dir)\n","test = get_dataset(data_test_dir, anns_test_dir)\n","if not os.path.exists('./pickles'):\n","    os.makedirs('./pickles')\n","pickle.dump(file = open('./pickles/train.pkl', 'wb'), obj = train)\n","pickle.dump(file = open('./pickles/valid.pkl', 'wb'), obj = valid)\n","pickle.dump(file = open('./pickles/test.pkl', 'wb'), obj = test)\n","\n","print(\"\\nTraining scans:\", len(train), \"\\t\\t Scan slices:\", np.sum([x.shape[2] for x,_ in train]), \n","      \"\\nValidation scans:\", len(valid), \"\\t\\t Scan slices:\", np.sum([x.shape[2] for x,_ in valid]), \n","      \"\\nTesting scans: \", len(test), \"\\t\\t Scan slices:\", np.sum([x.shape[2] for x,_ in test]))\n","print(\"Sample 3D scans' shapes:\", train[2][0].shape, valid[1][0].shape, test[9][0].shape) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q_z8dDIWe5Gj","colab_type":"code","colab":{}},"source":["train = pickle.load(file = open('./pickles/train.pkl', 'rb'))    \n","valid=pickle.load(file = open('./pickles/valid.pkl', 'rb'))     \n","test=pickle.load(file = open('./pickles/test.pkl', 'rb')) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6oKBZX8m5qha","colab_type":"code","colab":{}},"source":["img_id = 1\n","multi_slice_viewer(train[img_id][0], train[img_id][1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eTKRQhb86K7V","colab_type":"code","colab":{}},"source":["from collections import Counter\n","class_freq = {0:0, 1:0, 2:0}\n","for i in range(len(train)):\n","    for j in range(train[i][1].shape[2]):\n","        d = Counter(train[i][1][:,:,j].flatten())\n","        class_freq[0] += d[0]\n","        class_freq[1] += d[1]\n","        class_freq[2] += d[2]\n","print(\"Class frequencies in training set: \", class_freq)\n","\n","inv_class_freq = 1. / np.array([class_freq[0], class_freq[1], class_freq[2]], dtype=np.float64)\n","class_weights = inv_class_freq / sum(inv_class_freq)\n","print(\"Class weights (inversely proportional to class frequencies): \", class_weights)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CHxrLxaw6fRH","colab_type":"code","colab":{}},"source":["do_cross_val = True # Whether to do cross-validation\n","if do_cross_val:\n","    data_total = train + valid + test\n","    K_FOLD = 3\n","    VALID_FRAC = 0.25 # fraction of the training set used as validation set\n","    CURRENT_FOLD = 0  # need to be set to: 0, 1, ... K_FOLD-1\n","\n","    val_split = len(data_total)/K_FOLD\n","    val_idx = CURRENT_FOLD*val_split\n","    train = data_total[:val_idx] + data_total[val_idx+val_split:]\n","    valid = train[:int(len(train)*VALID_FRAC)]\n","    train = train[int(len(train)*VALID_FRAC):]\n","    test = data_total[val_idx:val_idx+val_split]\n","    data_total = []"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-6PBtCyH6n_W","colab_type":"code","colab":{}},"source":["def rotate(voxels, lbls, theta = None):\n","    # Rotate volume by a minor angle (+/- 10 degrees: determined by investigation of dataset variability)\n","    if theta is None:\n","        theta = random.randint(-10, 10)\n","    vox_new = scipy.ndimage.interpolation.rotate(voxels, theta, reshape = False)\n","    lbl_new = scipy.ndimage.interpolation.rotate(lbls, theta, reshape = False)\n","    return vox_new, lbl_new\n","\n","def scale_and_crop(voxels, lbls):\n","    # Scale the volume by a minor size and crop around centre (can also modify for random crop)\n","    o_s = voxels.shape\n","    r_s = [0]*len(o_s)\n","    scale_factor = random.uniform(1, 1.2)\n","    vox_zoom = scipy.ndimage.interpolation.zoom(voxels, scale_factor, order=1)\n","    lbl_zoom = scipy.ndimage.interpolation.zoom(lbls, scale_factor, order=0)\n","    new_shape = vox_zoom.shape\n","    # Start with offset\n","    for i in range(len(o_s)):\n","        if new_shape[i] == 1: \n","            r_s[i] = 0\n","            continue\n","        r_c = int(((new_shape[i] - o_s[i]) - 1)/2)\n","        r_s[i] = r_c\n","    r_e = [r_s[i] + o_s[i] for i in list(range(len(o_s)))]\n","    vox_zoom = vox_zoom[r_s[0]:r_e[0], r_s[1]:r_e[1], r_s[2]:r_e[2]]\n","    lbl_zoom = lbl_zoom[r_s[0]:r_e[0], r_s[1]:r_e[1], r_s[2]:r_e[2]]\n","    return vox_zoom, lbl_zoom\n","\n","def grayscale_variation(voxels, lbls):\n","    # Introduce a random global increment in gray-level value of volume. \n","    im_min = np.min(voxels)\n","    im_max = np.max(voxels)\n","    mean = np.random.normal(0, 0.1)\n","    smp = np.random.normal(mean, 0.01, size = np.shape(voxels))\n","    voxels = voxels + im_max*smp\n","    voxels[voxels <= im_min] = im_min # Clamp to min value\n","    voxels[voxels > im_max] = im_max  # Clamp to max value\n","    return voxels, lbls\n","\n","from scipy.ndimage.interpolation import map_coordinates\n","from scipy.ndimage.filters import gaussian_filter\n","\n","def elastic_deformation(voxels, lbls, alpha=None, sigma=None, mode=\"constant\", cval=0, is_random=False): \n","    if alpha == None:\n","        alpha=voxels.shape[1]*3.\n","    if sigma == None:\n","        sigma=voxels.shape[1]*0.07\n","    if is_random is False:\n","        random_state = np.random.RandomState(None)\n","    else:\n","        random_state = np.random.RandomState(int(time.time()))\n","        \n","    if len(voxels.shape) == 3:\n","        voxels = np.reshape(voxels, (voxels.shape[0], voxels.shape[1], voxels.shape[2], 1) )\n","        lbls = np.reshape(lbls, (lbls.shape[0], lbls.shape[1], lbls.shape[2], 1) )\n","        \n","    shape = (voxels.shape[0], voxels.shape[1])\n","    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=mode, cval=cval) * alpha\n","    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=mode, cval=cval) * alpha\n","    x_, y_ = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), indexing='ij')\n","    indices = np.reshape(x_ + dx, (-1, 1)), np.reshape(y_ + dy, (-1, 1))\n","    \n","    new_voxels = np.zeros(voxels.shape)\n","    new_lbls = np.zeros(lbls.shape)\n","    for i in range(voxels.shape[2]): # apply the same distortion to each slice within the volume\n","        new_voxels[:,:,i,0] = map_coordinates(voxels[:,:,i,0], indices, order=1).reshape(shape)\n","        new_lbls[:,:,i,0] = map_coordinates(lbls[:,:,i,0], indices, order=1).reshape(shape)\n","        \n","    return new_voxels, new_lbls\n","\n","def sample_with_p(p):\n","    # Helper function to return boolean of a sample with given probability p\n","    if random.random() < p:\n","        return True\n","    else:\n","        return False\n","\n","def get_random_perturbation(voxels, lbls):\n","    # Generate a random perturbation of the input feature + label\n","    p_rotate = 0.2\n","    p_scale = 0.2\n","    p_gray = 0.2\n","    p_deform = 0.2\n","    new_voxels, new_lbls = voxels, lbls\n","    if sample_with_p(p_rotate):\n","        new_voxels, new_lbls = rotate(new_voxels, new_lbls)\n","    if sample_with_p(p_scale):\n","        new_voxels, new_lbls = scale_and_crop(new_voxels, new_lbls)\n","    if sample_with_p(p_gray):\n","        new_voxels, new_lbls = grayscale_variation(new_voxels, new_lbls)\n","    if sample_with_p(p_deform):\n","        new_voxels, new_lbls = elastic_deformation(new_voxels, new_lbls)\n","    return new_voxels, new_lbls\n","\n","def plot_augmentation(img_org, ann_org, img_aug, ann_aug, title_aug='Augmented', axis_off=True):\n","    # Plot original and augmented image along with its annotation\n","    # Works for different kinds of augmentations\n","    if len(ann_org) == 0:\n","        n = 1 # Annotations are not plotted\n","    else:\n","        n = 2 # Annotations are plotted\n","    pl.figure(figsize=(5,5))\n","    pl.subplot(n,2,1)\n","    if axis_off:\n","        pl.axis('off')\n","    pl.title(\"Original scan\")\n","    pl.imshow(img_org, cmap=pl.cm.gray)\n","    pl.subplot(n,2,2)\n","    if axis_off:\n","        pl.axis('off')\n","    pl.title(title_aug)\n","    pl.imshow(img_aug, cmap=pl.cm.gray)\n","    if n > 1:\n","        pl.subplot(n,2,3)\n","        if axis_off:\n","            pl.axis('off')\n","        pl.title(\"Original annotation\")\n","        pl.imshow(ann_org, cmap=pl.cm.gray)\n","        pl.subplot(n,2,4)\n","        if axis_off:\n","            pl.axis('off')\n","        pl.title(title_aug)\n","        pl.imshow(ann_aug, cmap=pl.cm.gray)\n","    pl.tight_layout()\n","    pl.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xiITU7BJ6uB7","colab_type":"code","colab":{}},"source":["# Load the dataset if needed\n","#train = pickle.load(file = open('./pickles/train.pkl', 'rb'))\n","\n","img_id = 12\n","slice_id = 8\n","\n","imgs_org = train[img_id][0]\n","anns_org = train[img_id][1]\n","\n","img_org = train[img_id][0][:,:,slice_id]\n","ann_org = train[img_id][1][:,:,slice_id]\n","\n","# Rotation\n","imgs_aug, anns_aug = rotate(imgs_org, anns_org, theta=10)\n","plot_augmentation(img_org, ann_org, imgs_aug[:,:,slice_id], anns_aug[:,:,slice_id], title_aug='Rotation')\n","\n","# Scaling\n","imgs_aug, anns_aug = scale_and_crop(imgs_org, anns_org)\n","plot_augmentation(img_org, ann_org, imgs_aug[:,:,slice_id], anns_aug[:,:,slice_id], title_aug='Scaling')\n","\n","# Gray value variation\n","imgs_aug, anns_aug = grayscale_variation(imgs_org, anns_org)\n","plot_augmentation(img_org, [], imgs_aug[:,:,slice_id], [], title_aug='Gray variation')\n","\n","# Elastic deformation (smooth dense deformation field)\n","imgs_aug, anns_aug = elastic_deformation(imgs_org, anns_org)\n","plot_augmentation(img_org, ann_org, imgs_aug[:,:,slice_id,0], anns_aug[:,:,slice_id,0], title_aug='Elastic deformation')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nrv1LTh064c0","colab_type":"code","colab":{}},"source":["from skimage import exposure, img_as_float\n","\n","def hist_equalise(dataset):\n","    for i in range(len(dataset)): \n","        for j in range(dataset[i][0].shape[2]): \n","            dataset[i][0][:,:,j] = exposure.equalize_hist(dataset[i][0][:,:,j])\n","            \n","def plot_img_and_hist(image, axes, bins=100):\n","    image = img_as_float(image)\n","    ax_img, ax_hist = axes\n","    ax_cdf = ax_hist.twinx()\n","    \n","    # Display image\n","    ax_img.imshow(image, cmap=pl.cm.gray)\n","    ax_img.set_axis_off()\n","    \n","    # Display histogram\n","    ax_hist.hist(image.ravel(), bins=bins, histtype='step', color='black')\n","    ax_hist.ticklabel_format(axis='y', style='scientific', scilimits=(0, 0))\n","    ax_hist.set_xlabel('Pixel intensity')\n","    ax_hist.set_xlim(0, 1)\n","    ax_hist.set_yticks([])\n","\n","    # Display cumulative distribution\n","    img_cdf, bins = exposure.cumulative_distribution(image, bins)\n","    ax_cdf.plot(bins, img_cdf, 'r')\n","    ax_cdf.set_yticks([])\n","\n","    return ax_img, ax_hist, ax_cdf\n","\n","def plot_histogram_equalisation(img_org, img_heq):\n","    # Plot original low contrast image and histogram eualised image, with their histograms and cumulative histograms.\n","    # Code adapted from: http://scikit-image.org/docs/dev/auto_examples/color_exposure/plot_equalize.html\n","\n","    fig = pl.figure(figsize=(7, 7))\n","    axes = np.zeros((2, 2), dtype=np.object)\n","    axes[0, 0] = fig.add_subplot(2, 2, 1)\n","    for i in range(1, 2):\n","        axes[0, i] = fig.add_subplot(2, 2, 1+i, sharex=axes[0,0], sharey=axes[0,0])\n","    for i in range(0, 2):\n","        axes[1, i] = fig.add_subplot(2, 2, 3+i)\n","\n","    ax_img, ax_hist, ax_cdf = plot_img_and_hist(img_org, axes[:, 0])\n","    ax_img.set_title('Original low contrast image')\n","\n","    y_min, y_max = ax_hist.get_ylim()\n","    ax_hist.set_ylabel('Number of pixels')\n","    ax_hist.set_yticks(np.linspace(0, y_max, 5))\n","\n","    ax_img, ax_hist, ax_cdf = plot_img_and_hist(img_heq, axes[:, 1])\n","    ax_img.set_title('Histogram equalised image')\n","\n","    ax_cdf.set_ylabel('Fraction of total intensity', color='red')\n","    ax_cdf.set_yticks(np.linspace(0, 1, 5))\n","\n","    fig.tight_layout(h_pad=-1.5)\n","    pl.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HHjq-mK277K2","colab_type":"code","colab":{}},"source":["train = pickle.load(file = open('./pickles/train.pkl', 'rb'))\n","valid = pickle.load(file = open('./pickles/valid.pkl', 'rb'))\n","test = pickle.load(file = open('./pickles/test.pkl', 'rb'))\n","\n","hist_equalise(train) # in-place\n","hist_equalise(valid)\n","hist_equalise(test)\n","\n","# Save histogram equalised dataset\n","pickle.dump(file = open('./pickles/heq_train.pkl', 'wb'), obj = train)\n","pickle.dump(file = open('./pickles/heq_valid.pkl', 'wb'), obj = valid)\n","pickle.dump(file = open('./pickles/heq_test.pkl', 'wb'), obj = test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HZOuASAw9OTc","colab_type":"code","colab":{}},"source":["nhe_test = pickle.load(file = open('./pickles/test.pkl', 'rb'))\n","nhe_train = pickle.load(file = open('./pickles/train.pkl', 'rb'))\n","nhe_valid = pickle.load(file = open('./pickles/valid.pkl', 'rb'))\n","\n","#test = pickle.load(file = open('./pickles/heq_test.pkl', 'rb'))\n","img_id = 8\n","slice_id = 10\n","img = nhe_test[img_id][0][:,:,slice_id]\n","#img = img / np.max(img)\n","img_eq = test[img_id][0][:,:,slice_id]\n","plot_histogram_equalisation(img, img_eq)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QCtwKORcMZVL","colab_type":"code","colab":{}},"source":["import numpy as np \n","import matplotlib.pyplot as pl\n","import matplotlib\n","import tensorflow as tf\n","import os\n","import sys\n","import pydicom\n","import nrrd\n","import scipy.ndimage\n","import random\n","import pickle\n","%matplotlib notebook\n","\n","INPUT_SIZE = 120 # Input feature width/height\n","OUTPUT_SIZE = 120 # Output feature width/height (as defined by model)\n","INPUT_DEPTH = 12 # Input depth \n","OFF_IMAGE_FILL = 0 # What to fill an image with if padding is required to make Tensor\n","OFF_LABEL_FILL = 0 # What to fill a label with if padding is required to make Tensor\n","OUTPUT_CLASSES = 3 # Number of output classes in dataset: the fourth class can be used for unlabelled datapoints (not needed for this dataset)\n","\n","io_zoom = OUTPUT_SIZE/INPUT_SIZE\n","zero_chk = np.zeros((INPUT_SIZE, INPUT_SIZE, INPUT_DEPTH))\n","OUTPUT_DEPTH = np.shape(scipy.ndimage.interpolation.zoom(zero_chk, io_zoom, order = 1))[-1]\n","OUTPUT_DEPTH = 12 \n","\n","def get_scaled_input(data, min_i = INPUT_SIZE, min_o = OUTPUT_SIZE, depth = INPUT_DEPTH, \n","                    depth_out = OUTPUT_DEPTH, image_fill = OFF_IMAGE_FILL, \n","                    label_fill = OFF_LABEL_FILL, n_classes = OUTPUT_CLASSES, norm_max = 500):\n","    \n","    # Takes raw data (x, y) and scales to match desired input and output sizes to feed into Tensorflow\n","    # Pads and normalises input and also moves axes around to orientation expected by tensorflow\n","    \n","    input_scale_factor = min_i/data[0].shape[0]\n","    output_scale_factor = min_o/data[0].shape[0]\n","\n","    vox_zoom = None\n","    lbl_zoom = None\n","\n","    if not input_scale_factor == 1:\n","        vox_zoom = scipy.ndimage.interpolation.zoom(data[0], input_scale_factor, order = 1) \n","        # Order 1 is bilinear - fast and good enough\n","    else:\n","        vox_zoom = data[0]\n","\n","    if not output_scale_factor == 1:\n","        lbl_zoom = scipy.ndimage.interpolation.zoom(data[1], output_scale_factor, order = 0) \n","        # Order 0 is nearest neighbours: VERY IMPORTANT as it ensures labels are scaled properly (and stay discrete)\n","    else:\n","        lbl_zoom = data[1]   \n","\n","    lbl_pad = label_fill*np.ones((min_o, min_o, depth_out - lbl_zoom.shape[-1]))\n","    lbl_zoom = np.concatenate((lbl_zoom, lbl_pad), 2)\n","    lbl_zoom = lbl_zoom[np.newaxis, :, :, :]\n","    \n","    vox_pad = image_fill*np.ones((min_i, min_i, depth - vox_zoom.shape[-1]))\n","    vox_zoom = np.concatenate((vox_zoom, vox_pad), 2)\n","    \n","    max_val = np.max(vox_zoom)\n","    if not np.max(vox_zoom) == 0:\n","        vox_zoom = vox_zoom * norm_max/np.max(vox_zoom)\n","        \n","    vox_zoom = vox_zoom[np.newaxis, :, :, :]\n","\n","    vox_zoom = np.swapaxes(vox_zoom, 0, -1)\n","    lbl_zoom = np.swapaxes(lbl_zoom, 0, -1)\n","    # Swap axes\n","        \n","    return vox_zoom, lbl_zoom\n","\n","def upscale_segmentation(lbl, shape_desired):\n","    # Returns scaled up label for a given input label and desired shape. Required for Mean IOU calculation\n","    \n","    scale_factor = shape_desired[0]/lbl.shape[0]\n","    lbl_upscale = scipy.ndimage.interpolation.zoom(lbl, scale_factor, order = 0)\n","    lbl_upscale = lbl_upscale[:, :, :shape_desired[-1]]\n","    if lbl_upscale.shape[-1] < shape_desired[-1]:\n","        pad_zero = OFF_LABEL_FILL*np.zeros((shape_desired[0], shape_desired[1], shape_desired[2] - lbl_upscale.shape[-1]))\n","        lbl_upscale = np.concatenate((lbl_upscale, pad_zero), axis = -1)\n","    return lbl_upscale\n","\n","def get_label_accuracy(pred, lbl_original):\n","    # Get pixel-wise labelling accuracy (DEMO metric)\n","    \n","    # Swap axes back\n","    pred = swap_axes(pred)\n","    pred_upscale = upscale_segmentation(pred, np.shape(lbl_original))\n","    return 100*np.sum(np.equal(pred_upscale, lbl_original))/np.prod(lbl_original.shape)\n","\n","def get_mean_iou(pred, lbl_original, num_classes = OUTPUT_CLASSES, ret_full = False, reswap = False):\n","    # Get mean IOU between input predictions and target labels. Note, method implicitly resizes as needed\n","    # Ret_full - returns the full iou across all classes\n","    # Reswap - if lbl_original is in tensorflow format, swap it back into the format expected by plotting tools (+ format of raw data)\n","    \n","    # Swap axes back \n","    pred = swap_axes(pred)\n","    if reswap:\n","        lbl_original = swap_axes(lbl_original)\n","    pred_upscale = upscale_segmentation(pred, np.shape(lbl_original))\n","    iou = [1]*num_classes\n","    for i in range(num_classes): \n","        test_shape = np.zeros(np.shape(lbl_original))\n","        test_shape[pred_upscale == i] = 1\n","        test_shape[lbl_original == i] = 1\n","        full_sum = int(np.sum(test_shape))\n","        test_shape = -1*np.ones(np.shape(lbl_original))\n","        test_shape[lbl_original == i] = pred_upscale[lbl_original == i]\n","        t_p = int(np.sum(test_shape == i))\n","        if not full_sum == 0:\n","            iou[i] = t_p/full_sum\n","    if ret_full:\n","        return iou\n","    else: \n","        return np.mean(iou)\n","    \n","def swap_axes(pred):\n","    # Swap those axes\n","    pred = np.swapaxes(pred, -1, 0)\n","    pred = np.squeeze(pred)\n","    return pred"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pZq7RWVtOIHa","colab_type":"code","colab":{}},"source":["img_id = 9\n","dataset = test\n","x, y = get_scaled_input(dataset[img_id]) \n","x_swap = swap_axes(x)\n","y_upscale = upscale_segmentation(swap_axes(y), np.shape(swap_axes(x)))\n","multi_slice_viewer(x_swap, y_upscale)  \n","\n","# mean iou \n","x, y = get_scaled_input(dataset[img_id])\n","print('Mean IOU with itself')\n","print(get_mean_iou(y, y, ret_full = True, reswap = True))\n","print('Mean IOU with original labels')\n","print(get_mean_iou(y, dataset[img_id][1], ret_full = True, reswap = False))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bV5-Axg-dTTL","colab_type":"code","colab":{}},"source":["simpleUNet = False\n","\n","class UNetwork():\n","    \n","    def conv_batch_relu(self, tensor, filters, kernel = [3,3,3], stride = [1,1,1], is_training = True):\n","        padding = 'valid'\n","        if self.should_pad: padding = 'same'\n","    \n","        conv = tf.layers.conv3d(tensor, filters, kernel_size = kernel, strides = stride, padding = padding,\n","                                kernel_initializer = self.base_init, kernel_regularizer = self.reg_init)\n","        conv = tf.layers.batch_normalization(conv, training = is_training)\n","        conv = tf.nn.relu(conv) \n","        return conv\n","\n","    def upconvolve(self, tensor, filters, kernel = 2, stride = 2, scale = 4, activation = None):\n","        padding = 'valid'\n","        if self.should_pad: padding = 'same'\n","        conv = tf.layers.conv3d_transpose(tensor, filters, kernel_size = kernel, strides = stride, padding = padding, use_bias=False, \n","                                          kernel_initializer = self.base_init,  kernel_regularizer = self.reg_init)\n","        return conv\n","\n","    def centre_crop_and_concat(self, prev_conv, up_conv):\n","        p_c_s = prev_conv.get_shape()\n","        u_c_s = up_conv.get_shape()\n","        offsets =  np.array([0, (p_c_s[1] - u_c_s[1]) // 2, (p_c_s[2] - u_c_s[2]) // 2, \n","                             (p_c_s[3] - u_c_s[3]) // 2, 0], dtype = np.int32)\n","        size = np.array([-1, u_c_s[1], u_c_s[2], u_c_s[3], p_c_s[4]], np.int32)\n","        prev_conv_crop = tf.slice(prev_conv, offsets, size)\n","        up_concat = tf.concat((prev_conv_crop, up_conv), 4)\n","        return up_concat\n","        \n","    def __init__(self, base_filt = 8, in_depth = INPUT_DEPTH, out_depth = OUTPUT_DEPTH,\n","                 in_size = INPUT_SIZE, out_size = OUTPUT_SIZE, num_classes = OUTPUT_CLASSES,\n","                 learning_rate = 0.001, print_shapes = True, drop = 0.2, should_pad = False):\n","        \n","        self.base_init = tf.truncated_normal_initializer(stddev=0.2) \n","        self.reg_init = tf.contrib.layers.l2_regularizer(scale=0.2) \n","        \n","        self.should_pad = should_pad \n","        self.drop = drop \n","        \n","        with tf.variable_scope('3DuNet'):\n","            self.training = tf.placeholder(tf.bool)\n","            self.do_print = print_shapes\n","            self.model_input = tf.placeholder(tf.float32, shape = (None, in_depth, in_size, in_size, 1))  \n","            self.model_labels = tf.placeholder(tf.int32, shape = (None, out_depth, out_size, out_size, 1))\n","            labels_one_hot = tf.squeeze(tf.one_hot(self.model_labels, num_classes, axis = -1), axis = -2)\n","            \n","            if self.do_print: \n","                print('Input features shape', self.model_input.get_shape())\n","                print('Labels shape', labels_one_hot.get_shape())\n","                \n","            # Level zero\n","            conv_0_1 = self.conv_batch_relu(self.model_input, base_filt, is_training = self.training)\n","            conv_0_2 = self.conv_batch_relu(conv_0_1, base_filt*2, is_training = self.training)\n","            # Level one\n","            max_1_1 = tf.layers.max_pooling3d(conv_0_2, [1,2,2], [1,2,2]) # Stride, Kernel previously [2,2,2]\n","            conv_1_1 = self.conv_batch_relu(max_1_1, base_filt*2, is_training = self.training)\n","            conv_1_2 = self.conv_batch_relu(conv_1_1, base_filt*4, is_training = self.training)\n","            conv_1_2 = tf.layers.dropout(conv_1_2, rate = self.drop, training = self.training)\n","            # Level two\n","            max_2_1 = tf.layers.max_pooling3d(conv_1_2, [1,2,2], [1,2,2]) # Stride, Kernel previously [2,2,2]\n","            conv_2_1 = self.conv_batch_relu(max_2_1, base_filt*4, is_training = self.training)\n","            conv_2_2 = self.conv_batch_relu(conv_2_1, base_filt*8, is_training = self.training)\n","            conv_2_2 = tf.layers.dropout(conv_2_2, rate = self.drop, training = self.training)\n","            \n","            if simpleUNet:\n","                # Level one\n","                up_conv_2_1 = self.upconvolve(conv_2_2, base_filt*8, kernel = 2, stride = [1,2,2]) # Stride previously [2,2,2]\n","            else:\n","                # Level three\n","                max_3_1 = tf.layers.max_pooling3d(conv_2_2, [1,2,2], [1,2,2]) # Stride, Kernel previously [2,2,2]\n","                conv_3_1 = self.conv_batch_relu(max_3_1, base_filt*8, is_training = self.training)\n","                conv_3_2 = self.conv_batch_relu(conv_3_1, base_filt*16, is_training = self.training)\n","                conv_3_2 = tf.layers.dropout(conv_3_2, rate = self.drop, training = self.training)\n","                # Level two\n","                up_conv_3_2 = self.upconvolve(conv_3_2, base_filt*16, kernel = 2, stride = [1,2,2]) # Stride previously [2,2,2] \n","                concat_2_1 = self.centre_crop_and_concat(conv_2_2, up_conv_3_2)\n","                conv_2_3 = self.conv_batch_relu(concat_2_1, base_filt*8, is_training = self.training)\n","                conv_2_4 = self.conv_batch_relu(conv_2_3, base_filt*8, is_training = self.training)\n","                conv_2_4 = tf.layers.dropout(conv_2_4, rate = self.drop, training = self.training)\n","                # Level one\n","                up_conv_2_1 = self.upconvolve(conv_2_4, base_filt*8, kernel = 2, stride = [1,2,2]) # Stride previously [2,2,2]\n","            \n","            concat_1_1 = self.centre_crop_and_concat(conv_1_2, up_conv_2_1)\n","            conv_1_3 = self.conv_batch_relu(concat_1_1, base_filt*4, is_training = self.training)\n","            conv_1_4 = self.conv_batch_relu(conv_1_3, base_filt*4, is_training = self.training)\n","            conv_1_4 = tf.layers.dropout(conv_1_4, rate = self.drop, training = self.training)\n","            # Level zero\n","            up_conv_1_0 = self.upconvolve(conv_1_4, base_filt*4, kernel = 2, stride = [1,2,2])  # Stride previously [2,2,2]\n","            concat_0_1 = self.centre_crop_and_concat(conv_0_2, up_conv_1_0)\n","            conv_0_3 = self.conv_batch_relu(concat_0_1, base_filt*2, is_training = self.training)\n","            conv_0_4 = self.conv_batch_relu(conv_0_3, base_filt*2, is_training = self.training)\n","            conv_0_4 = tf.layers.dropout(conv_0_4, rate = self.drop, training = self.training)\n","            conv_out = tf.layers.conv3d(conv_0_4, OUTPUT_CLASSES, [1,1,1], [1,1,1], padding = 'same')\n","            self.predictions = tf.expand_dims(tf.argmax(conv_out, axis = -1), -1)\n","            \n","            \n","            if self.do_print: \n","                print('Model Convolution output shape', conv_out.get_shape())\n","                print('Model Argmax output shape', self.predictions.get_shape())\n","            \n","            do_weight = True\n","            loss_weights = [0.00439314, 0.68209101, 0.31351585] \n","            ce_loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=conv_out, labels=labels_one_hot)\n","            if do_weight:\n","                weighted_loss = tf.reshape(tf.constant(loss_weights), [1, 1, 1, 1, num_classes]) # Format to the right size\n","                weighted_one_hot = tf.reduce_sum(weighted_loss*labels_one_hot, axis = -1)\n","                ce_loss = ce_loss * weighted_one_hot\n","            self.loss = tf.reduce_mean(ce_loss) # Get loss\n","            \n","            self.trainer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","            \n","            self.extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n","            with tf.control_dependencies(self.extra_update_ops):\n","                self.train_op = self.trainer.minimize(self.loss)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iK9m877eO3U4","colab_type":"code","colab":{}},"source":["train = pickle.load(file = open('./pickles/heq_train.pkl', 'rb'))\n","valid = pickle.load(file = open('./pickles/heq_valid.pkl', 'rb'))\n","test = pickle.load(file = open('./pickles/heq_test.pkl', 'rb'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D3bJyNv2PsiJ","colab_type":"code","colab":{}},"source":["#d=[]\n","#while(1):\n"," # d.append('1')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eyac53o8WQTc","colab_type":"code","colab":{}},"source":["train_run = []\n","#augment_len = 5 \n","for i in train:\n","    (vox, lbl) = get_scaled_input(i)\n","    train_run.append((vox, lbl))\n","    #for j in range(augment_len):\n","     #   vox_a, lbl_a = get_random_perturbation(vox, lbl)\n","    train_run.append((vox_a, lbl_a))\n","        \n","# Validation\n","valid_run = []\n","for i in valid:\n","    (vox, lbl) = get_scaled_input(i)\n","    valid_run.append((vox, lbl))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ywosu2ciW4Qr","colab_type":"code","colab":{}},"source":["LEARNING_RATE = 0.001 # Model learning rate\n","DROPOUT = 0.2\n","BASE_FILT = 16    # Number of base filters\n","BATCH_SIZE = 5  # Batch size - VRAM limited; originally 3\n","PATIENCE = 5     # For early stopping: watching for validation loss increase\n","NUM_EPOCHS = 100 # Maximum number of training epochs\n","NUM_ITER = len(train_run) // BATCH_SIZE # Number of training steps per epoch\n","MODEL_NAME = 'FIN10a1d8f' # Model name to LOAD FROM (looks IN SAVE_PATH directory)\n","SAVE_PATH = \"./tf/\" \n","LOGS_PATH = \"./tf_logs/\"\n","LOAD_MODEL = True\n","if not os.path.exists(SAVE_PATH):\n","    os.makedirs(SAVE_PATH)\n","if not os.path.exists(LOGS_PATH):\n","    os.makedirs(LOGS_PATH)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3KRZtLxNXVn-","colab_type":"code","colab":{}},"source":["def get_data_raw(data, i, batch_size):\n","    return [x[0] for x in data[i:i+batch_size]], [y[1] for y in data[i:i+batch_size]]\n","\n","def get_pred_iou(predictions, lbl_original, ret_full = False, reswap = False):\n","    iou = []\n","    for i in range(len(lbl_original)):\n","        pred_cur = np.squeeze(predictions[i])\n","        metric = get_mean_iou(pred_cur, lbl_original[i], ret_full = ret_full, reswap = reswap)\n","        iou.append(metric)\n","    if ret_full:\n","        return np.mean(iou, axis = 0)\n","    else:\n","        return np.mean(iou)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rBehOmzHXXUz","colab_type":"code","outputId":"5beaab39-e26f-4572-a085-e7c8311b9beb","executionInfo":{"status":"error","timestamp":1581268643507,"user_tz":-330,"elapsed":14003,"user":{"displayName":"Sayantan Bhattacharya ASET, Noida","photoUrl":"","userId":"05093251328778821152"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["print(NUM_ITER, \" iterations per epoch\")\n","tf.reset_default_graph()\n","unet = UNetwork(drop = DROPOUT, base_filt = BASE_FILT, should_pad = True, learning_rate = LEARNING_RATE ) # MODEL DEFINITION\n","init = tf.global_variables_initializer()\n","saver = tf.train.Saver(tf.global_variables(), max_to_keep=4 *PATIENCE)\n","config = tf.ConfigProto()\n","\n","with tf.Session(config=config) as sess:\n","    writer = tf.summary.FileWriter(LOGS_PATH, graph=tf.get_default_graph())\n","    if LOAD_MODEL:\n","        print('Trying to load saved model...')\n","        try:\n","            print('Loading from: ', SAVE_PATH + MODEL_NAME+ '.meta')\n","            restorer = tf.train.import_meta_graph(SAVE_PATH + MODEL_NAME+ '.meta')\n","            restorer.restore(sess, tf.train.latest_checkpoint(SAVE_PATH))\n","            print(\"Model sucessfully restored\")\n","        except IOError:\n","            sess.run(init)\n","            print(\"No previous model found, running default init\") \n","    \n","    train_losses = []\n","    #val_losses = []\n","    tr_IOUs = []\n","    patience_cnt = 0\n","    train_times = []\n","    \n","    for e in range(NUM_EPOCHS):\n","        \n","        start_time = time.time()\n","        \n","        # Shuffle the training data\n","        random.shuffle(train_run)\n","        \n","        #curr_train_loss = []\n","        #for i in range(NUM_ITER): # Iterate over batches within the epoch\n","            #print('Current epoch: ',e,', iteration: ',i,'/',NUM_ITER, end='\\r')\n","            #x, y = get_data_raw(train_run, i, BATCH_SIZE)\n","            #_, orig_y = get_data_raw(train, i, len(train))    # non-scaled (for IOU evaluation)\n","            #train_dict = {\n","            #    unet.training: False,\n","             #   unet.model_input: x,\n","              #  unet.model_labels: y\n","            #}\n","            #train_loss = sess.run([unet.train_op, unet.loss], feed_dict = train_dict)\n","            #curr_train_loss.append(loss)\n","            #train_loss = np.mean(curr_train_loss)\n","\n","            \n","        # Evaluate and to get valid loss\n","        for i in range(NUM_ITER):\n","            x, y = get_data_raw(train_run, i, len(train_run)) # scaled\n","            _, orig_y = get_data_raw(train, i, len(train))    # non-scaled (for IOU evaluation)\n","            valid_dict = {\n","                unet.training: True,\n","                unet.model_input: x,\n","                unet.model_labels: y\n","         }\n","        train_loss = sess.run(unet.loss, feed_dict = valid_dict) \n","    \n","        # Predict on validation set IOU\n","        #val_preds = np.squeeze(sess.run([unet.predictions], feed_dict = valid_dict))\n","        tr_preds = np.squeeze(sess.run([unet.predictions], feed_dict = train_dict))\n","        iou = get_pred_iou(tr_preds, orig_y, ret_full = True)\n","        tr_IOUs.append(iou)\n","        \n","        train_losses.append(train_loss)\n","        #val_losses.append(val_loss)\n","        print(\"Epoch \",e, \"\\t train_loss = \", train_loss,  \"\\t tr_IOU = \", np.mean(iou))\n","        \n","        if e > 0:\n","            start_time = train_times[-1]\n","            if e % 5 == 0:\n","                print('Saving model at epoch: ', e) # Save periodically\n","                saver.save(sess, SAVE_PATH + MODEL_NAME, global_step = e)\n","\n","            if train_losses[-1] > train_losses[-2]:\n","                patience_cnt += 1\n","            else:\n","                patience_cnt = 0\n","                \n","        train_times.append( time.time() - start_time )\n","        \n","        if patience_cnt >= PATIENCE:\n","            print(\"Early stopping ...\")\n","            saver.save(sess, SAVE_PATH + MODEL_NAME + '-final', global_step = e)\n","            break\n","            "],"execution_count":108,"outputs":[{"output_type":"stream","text":["24  iterations per epoch\n","Input features shape (?, 12, 120, 120, 1)\n","Labels shape (?, 12, 120, 120, 3)\n","Model Convolution output shape (?, 12, 120, 120, 3)\n","Model Argmax output shape (?, 12, 120, 120, 1)\n","Trying to load saved model...\n","Loading from:  ./tf/FIN10a1d8f.meta\n","No previous model found, running default init\n"],"name":"stdout"},{"output_type":"error","ename":"NotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) Not found: No algorithm worked!\n\t [[{{node 3DuNet/conv3d_transpose_2/conv3d_transpose}}]]\n  (1) Not found: No algorithm worked!\n\t [[{{node 3DuNet/conv3d_transpose_2/conv3d_transpose}}]]\n\t [[3DuNet/Mean/_9]]\n0 successful operations.\n0 derived errors ignored.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-108-6c727489503f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0munet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m          }\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Predict on validation set IOU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) Not found: No algorithm worked!\n\t [[node 3DuNet/conv3d_transpose_2/conv3d_transpose (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n  (1) Not found: No algorithm worked!\n\t [[node 3DuNet/conv3d_transpose_2/conv3d_transpose (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\t [[3DuNet/Mean/_9]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for '3DuNet/conv3d_transpose_2/conv3d_transpose':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-108-6c727489503f>\", line 3, in <module>\n    unet = UNetwork(drop = DROPOUT, base_filt = BASE_FILT, should_pad = True, learning_rate = LEARNING_RATE ) # MODEL DEFINITION\n  File \"<ipython-input-72-e781c4c5c94a>\", line 90, in __init__\n    up_conv_1_0 = self.upconvolve(conv_1_4, base_filt*4, kernel = 2, stride = [1,2,2])  # Stride previously [2,2,2]\n  File \"<ipython-input-72-e781c4c5c94a>\", line 19, in upconvolve\n    kernel_initializer = self.base_init,  kernel_regularizer = self.reg_init)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py\", line 1453, in conv3d_transpose\n    return layer.apply(inputs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 1700, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py\", line 548, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 854, in __call__\n    outputs = call_fn(cast_inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 234, in wrapper\n    return converted_call(f, options, args, kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 439, in converted_call\n    return _call_unconverted(f, args, kwargs, options)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 330, in _call_unconverted\n    return f(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py\", line 1117, in call\n    padding=self.padding.upper())\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\", line 2531, in conv3d_transpose\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\", line 2597, in conv3d_transpose_v2\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py\", line 2070, in conv3d_backprop_input_v2\n    dilations=dilations, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"]}]},{"cell_type":"markdown","metadata":{"id":"jp1jASOa1vdV","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"tGlkx7-Qke_X","colab_type":"code","colab":{}},"source":["np.savez('./' + MODEL_NAME + '.npz', train_losses=train_losses, val_losses=val_losses, val_IOUs=val_IOUs, \n","         train_times=train_times)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bDDE7GC_knpq","colab_type":"code","colab":{}},"source":["MODEL_NAME = 'FIN10a1d8f'\n","hist = np.load('./' + MODEL_NAME + '.npz')\n","train_losses = hist['train_losses']\n","val_losses = hist['val_losses']\n","val_IOUs = hist['val_IOUs']\n","train_times = hist['train_times']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s7gNL2LNk6La","colab_type":"code","colab":{}},"source":["mean_val_IOUs = [np.mean(iou) for iou in val_IOUs]\n","print(\"Minimum validation loss: \", np.min(val_losses), \" at epoch \", np.argmin(val_losses))\n","print(\"Maximum validation IOU: \", np.max(mean_val_IOUs), \" at epoch \", np.argmax(mean_val_IOUs))\n","print(\"Last validation loss: \", val_losses[-1])\n","print(\"Last validation IOU: \", mean_val_IOUs[-1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QAKtt4-fepyM","colab_type":"code","colab":{}},"source":["# Validation IOU\n","pl.figure()\n","pl.plot(x, mean_val_IOUs,'b-')\n","pl.xlabel('Epoch')\n","pl.ylabel('Validatio IOU')\n","pl.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DX7Vvtdwe9q9","colab_type":"code","colab":{}},"source":["# Loss Curves\n","pl.figure()\n","x = np.arange(len(train_losses))\n","pl.plot(x, train_losses,'r-')\n","pl.plot(x, val_losses,'b-')\n","pl.legend(['Training loss', 'Validation loss'])\n","pl.xlabel('Epoch')\n","pl.ylabel('Loss')\n","pl.ylim(0, 0.1)\n","pl.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i3vRnmJnnNhv","colab_type":"code","colab":{}},"source":["TEST_MODEL_NAME = 'FIN10a1d8f-20'\n","SAVE_PATH = \"./tf/\" \n","BATCH_SIZE = 12 # was 3 originally\n","\n","# Load the test set\n","test = pickle.load(file = open('./pickles/heq_test.pkl', 'rb'))\n","\n","config = tf.ConfigProto()\n","test_predictions = []\n","with tf.Session(config=config) as sess:\n","    print('Loading saved model ...')\n","    restorer = tf.train.import_meta_graph(SAVE_PATH + TEST_MODEL_NAME + '.meta')\n","    restorer.restore(sess, SAVE_PATH + TEST_MODEL_NAME)\n","    print(\"Model sucessfully restored\")\n","    pred_out = [] # Predictions for each test scan\n","    x_orig = []   # list of non-scaled scans\n","    y_orig = []   # list of non-scaled annotations\n","    x_in = []\n","    y_in = []\n","    i = 0\n","    iou_out = []  # IOUs for each test scan\n","\n","    while i < len(test): # Iterate over batches\n","        x_batch = []\n","        y_batch = []\n","        for j in range(i, min(len(test), i + BATCH_SIZE)): # Iterate over samples within the batch\n","            x_orig.append(np.copy(test[j][0]))\n","            y_orig.append(np.copy(test[j][1]))\n","            x_cur, y_cur = get_scaled_input(test[j])\n","            x_batch.append(x_cur)\n","            y_batch.append(y_cur)\n","        if len(x_batch) == 0: break\n","        print('Processing ', i)\n","        x_in = x_in + x_batch\n","        y_in = y_in + y_batch\n","        test_dict = {\n","            unet.training: False, # Whether to perform batch-norm at inference (Paper says this would be useful)\n","            unet.model_input: x_batch,\n","            unet.model_labels: y_batch\n","        }\n","        test_predictions = np.squeeze(sess.run([unet.predictions], feed_dict = test_dict))\n","        if len(x_batch) == 1:\n","            pred_out.append(test_predictions)\n","        else:\n","            pred_out.extend([np.squeeze(test_predictions[z, :, :, :]) for z in list(range(len(x_batch)))])\n","        i += BATCH_SIZE\n","\n","    for i in range(len(y_orig)):\n","        iou = get_mean_iou(pred_out[i], y_orig[i], ret_full = True)\n","        print('Test scan', i,': IOUs: ', iou, 'Mean: ', np.mean(iou))\n","        iou_out.append(np.mean(iou))\n","    print('Mean test IOU', np.mean(iou_out), 'Std IOU', np.std(iou_out)) # mean over all test scans\n","    \n","# Save test predictions\n","pickle.dump(file = open('./pickles/pred_' + TEST_MODEL_NAME + '.pkl', 'wb'), obj = pred_out)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oWP_Rr9Bnsp7","colab_type":"code","colab":{}},"source":["img_id = 2\n","x_cur = x_orig[img_id]\n","y_cur = y_orig[img_id]\n","y_upscale = upscale_segmentation(swap_axes(pred_out[img_id][:, :, :, np.newaxis]), np.shape(x_cur))\n","multi_slice_viewer(x_cur, y_cur, y_upscale) # View  images, labels and predictions together"],"execution_count":0,"outputs":[]}]}